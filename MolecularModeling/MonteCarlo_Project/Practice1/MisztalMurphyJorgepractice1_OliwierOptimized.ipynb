{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84867c02",
   "metadata": {},
   "source": [
    "## Oliwier Misztal   --------------   December 2, 2025\n",
    "## Arthur Murphy\n",
    "## Javi Jorge\n",
    "# Molecular Modeling - Monte Carlo Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7cfeae49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling functions...\n",
      "Compilation complete. Starting simulation...\n",
      "L=100, T=2.27, MCS=5000\n",
      "Time elapsed: 4.7587 s\n",
      "Speed: 1.05e+07 updates/second\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numba import njit\n",
    "import time\n",
    "\n",
    "# At first, we implement functions that are compiled with Numba for speed.\n",
    "\n",
    "@njit\n",
    "def create_nbr(L):\n",
    "    \"\"\"\n",
    "    Creates the neighbor table for a 2D square lattice.\n",
    "    Returns an array of shape (N, 4).\n",
    "    \"\"\"\n",
    "    N = L * L\n",
    "    nbr = np.zeros((N, 4), dtype=np.int64)\n",
    "    \n",
    "    # Pre-compute shifts (Periodic Boundaries)\n",
    "    ip = np.arange(L) + 1\n",
    "    im = np.arange(L) - 1\n",
    "    ip[L - 1] = 0\n",
    "    im[0] = L - 1\n",
    "    \n",
    "    for y in range(L):\n",
    "        for x in range(L):\n",
    "            i = x + y * L\n",
    "            nbr[i, 0] = ip[x] + y * L   # Right neighbor\n",
    "            nbr[i, 1] = im[x] + y * L   # Left neighbor\n",
    "            nbr[i, 2] = x + ip[y] * L   # Up neighbor\n",
    "            nbr[i, 3] = x + im[y] * L   # Down neighbor\n",
    "            \n",
    "    return nbr\n",
    "\n",
    "@njit\n",
    "def precompute_exponentials(T, nbr):\n",
    "    \"\"\"\n",
    "    Analyzes the neighbor table to find 'z' (coordination number)\n",
    "    and pre-computes the exponential table for all possible\n",
    "    positive Delta E values.\n",
    "    \"\"\"\n",
    "    beta = 1.0 / T\n",
    "    \n",
    "    # We analyze neighbors (nbr) to find 'z'\n",
    "    # We assume a regular lattice where every site has the same number of neighbors.\n",
    "    z = nbr.shape[1]  \n",
    "    \n",
    "    # We determine maximum possible energy change\n",
    "    # Maximum change happens when flipping a spin surrounded by aligned neighbors.\n",
    "    # Delta E = 2 * s_i * sum(neighbors). Max sum is z.\n",
    "    # Max Delta E = 2 * 1 * z = 2z\n",
    "    max_delta_E = 2 * z\n",
    "    \n",
    "    # We create the table\n",
    "    # We need indices up to max_delta_E. \n",
    "    exp_table = np.zeros(max_delta_E + 1, dtype=np.float64)\n",
    "    \n",
    "    # We fill valid Delta E values\n",
    "    # The sum of neighbors (h_i) goes from z down to -z in steps of 2.\n",
    "    # We only care about POSITIVE Delta E (where we need the probability).\n",
    "    # This corresponds to neighbor sums: z, z-2, z-4 ... > 0\n",
    "    current_sum = z\n",
    "    while current_sum > 0:\n",
    "        delta_E = 2 * current_sum\n",
    "        exp_table[delta_E] = np.exp(-beta * delta_E)\n",
    "        current_sum -= 2\n",
    "        \n",
    "    return exp_table\n",
    "\n",
    "@njit\n",
    "def metropolis_step(state, nbr, exp_table):\n",
    "    \"\"\"\n",
    "    Performs 1 Full Monte Carlo Step (N attempted flips).\n",
    "    This is highly optimized machine code loop.\n",
    "    \"\"\"\n",
    "    N = state.shape[0]\n",
    "    z = nbr.shape[1] # Number of neighbors\n",
    "    \n",
    "    # Loop N times (1 MCS)\n",
    "    for _ in range(N):\n",
    "        # Pick random site\n",
    "        i = np.random.randint(0, N)\n",
    "        s_i = state[i]\n",
    "        \n",
    "        # Calculate sum of neighbors (Generic loop for any z)\n",
    "        h_i = 0\n",
    "        for k in range(z):\n",
    "            h_i += state[nbr[i, k]]\n",
    "        \n",
    "        # Energy change\n",
    "        delta_E = 2 * s_i * h_i\n",
    "        \n",
    "        # Metropolis Acceptance\n",
    "        if delta_E <= 0:\n",
    "            state[i] = -s_i # Accept & Flip\n",
    "        else:\n",
    "            # Look up probability\n",
    "            if np.random.random() < exp_table[delta_E]:\n",
    "                state[i] = -s_i # Accept & Flip\n",
    "                \n",
    "    return state\n",
    "\n",
    "@njit\n",
    "def measure_observables(state, nbr):\n",
    "    \"\"\"\n",
    "    Calculates total Magnetization (M) and Energy (E) of the current state.\n",
    "    \"\"\"\n",
    "    N = state.shape[0]\n",
    "    z = nbr.shape[1]\n",
    "    M = 0\n",
    "    E = 0.0\n",
    "    for i in range(N):\n",
    "        M += state[i]\n",
    "        \n",
    "        # Calculate sum of neighbors for energy\n",
    "        h_i = 0\n",
    "        for k in range(z):\n",
    "            h_i += state[nbr[i, k]]\n",
    "            \n",
    "        # E = - sum(s_i * s_j). \n",
    "        # We divide by 2.0 at the end to correct for double counting.\n",
    "        E -= state[i] * h_i\n",
    "    return E / 2.0, M\n",
    "\n",
    "# Main Simulation Function\n",
    "\n",
    "def run_simulation(L=100, T=2.27, mcs_steps=10000, n_meas=100, spins=None):\n",
    "    # Setup\n",
    "    N = L * L\n",
    "    \n",
    "    # Geometry\n",
    "    nbr = create_nbr(L)\n",
    "    \n",
    "    # Smart Precalculation\n",
    "    # This automatically detects if z=4 (square), z=6 (triangular), etc.\n",
    "    exp_table = precompute_exponentials(T, nbr)\n",
    "\n",
    "    # Pre-allocate arrays for measurements\n",
    "    num_measurements = mcs_steps // n_meas\n",
    "    energies = np.zeros(num_measurements, dtype=np.float64)\n",
    "    magnetizations = np.zeros(num_measurements, dtype=np.int64)\n",
    "    \n",
    "    # Initialize Spins if not provided\n",
    "    if spins is None:\n",
    "        spins = np.random.choice(np.array([-1, 1], dtype=np.int8), size=N)\n",
    "    \n",
    "    # We need to JIT compile the functions before timing\n",
    "    # So we run once with dummy data to force Numba to compile\n",
    "    print(\"Compiling functions...\")\n",
    "    _ = metropolis_step(spins.copy(), nbr, exp_table)\n",
    "    print(\"Compilation complete. Starting simulation...\")\n",
    "    \n",
    "    # Start Timing\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Run the optimized loop\n",
    "    for step in range(mcs_steps):\n",
    "        metropolis_step(spins, nbr, exp_table)\n",
    "        # Measurement\n",
    "        if step % n_meas == 0:\n",
    "            idx = step // n_meas - 1\n",
    "            E, M = measure_observables(spins, nbr)\n",
    "            energies[idx] = E\n",
    "            magnetizations[idx] = M\n",
    "        \n",
    "    end_time = time.time()\n",
    "    elapsed = end_time - start_time\n",
    "    \n",
    "    # Statistics\n",
    "    total_flips = N * mcs_steps\n",
    "    flips_per_sec = total_flips / elapsed\n",
    "    \n",
    "    print(f\"L={L}, T={T}, MCS={mcs_steps}\")\n",
    "    print(f\"Time elapsed: {elapsed:.4f} s\")\n",
    "    print(f\"Speed: {flips_per_sec:.2e} updates/second\")\n",
    "    \n",
    "    return spins, energies, magnetizations\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Test with 3 example files:\n",
    "     #\n",
    "    run_simulation(L=100, T=2.27, mcs_steps=5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8d9d1d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_configuration(filename):\n",
    "    data = np.loadtxt(filename, dtype=int)\n",
    "    spins = data[:, 1]\n",
    "    return spins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ddf46fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_systems(L, initial_state='random', filename=None):\n",
    "    N = L * L\n",
    "    if initial_state == 'random':\n",
    "        spins = np.random.choice(np.array([-1, 1], dtype=np.int8), size=N)\n",
    "    elif initial_state == 'file' and filename is not None:\n",
    "        spins = read_configuration(filename)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid initial state or filename not provided.\")\n",
    "    return spins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "92accddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def calc_energy_vectorized(state, nbr):\n",
    "    energy = -np.sum(state[nbr] * state[:, None])\n",
    "    return energy/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebea79b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-8.0, 8)\n",
      "(-8.0, 8)\n",
      "(8.0, -4)\n",
      "(0.0, -4)\n",
      "(-4.0, -6)\n",
      "Time taken for measure_observables: 0.000782 seconds\n",
      "-8.0\n",
      "8.0\n",
      "0.0\n",
      "-4.0\n",
      "Time taken for calc_energy_vectorized: 0.000692 seconds\n"
     ]
    }
   ],
   "source": [
    "L = 10\n",
    "nbr = create_nbr(L)\n",
    "N = L * L\n",
    "spins_test_configuration = initialize_systems(L, initial_state='file', filename='test_configuration.dat')\n",
    "spins_mys1 = initialize_systems(L, initial_state='file', filename='mys1.dat')\n",
    "spins_mys2 = initialize_systems(L, initial_state='file', filename='mys2.dat')\n",
    "spins_mys3 = initialize_systems(L, initial_state='file', filename='mys3.dat')\n",
    "\n",
    "print(measure_observables(spins_test_configuration, nbr))\n",
    "start_time = time.time()\n",
    "print(measure_observables(spins_test_configuration, nbr))\n",
    "print(measure_observables(spins_mys1, nbr))\n",
    "print(measure_observables(spins_mys2, nbr))\n",
    "print(measure_observables(spins_mys3, nbr))\n",
    "end_time = time.time()\n",
    "print(f\"Time taken for measure_observables: {end_time - start_time:.6f} seconds\")\n",
    "\n",
    "start_time = time.time()\n",
    "print(calc_energy_vectorized(spins_test_configuration, nbr))\n",
    "print(calc_energy_vectorized(spins_mys1, nbr))\n",
    "print(calc_energy_vectorized(spins_mys2, nbr))\n",
    "print(calc_energy_vectorized(spins_mys3, nbr))\n",
    "end_time = time.time()\n",
    "print(f\"Time taken for calc_energy_vectorized: {end_time - start_time:.6f} seconds\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2dd4ed52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-868.0, 1990)\n",
      "(-868.0, 1990)\n",
      "Time taken for measure_observables: 0.015276 seconds\n",
      "-868.0\n",
      "Time taken for calc_energy_vectorized: 0.040495 seconds\n"
     ]
    }
   ],
   "source": [
    "L = 1000\n",
    "nbr = create_nbr(L)\n",
    "N = L * L\n",
    "spins_test_configuration = initialize_systems(L, initial_state=\"random\")\n",
    "\n",
    "print(measure_observables(spins_test_configuration, nbr))\n",
    "start_time = time.time()\n",
    "print(measure_observables(spins_test_configuration, nbr))\n",
    "end_time = time.time()\n",
    "print(f\"Time taken for measure_observables: {end_time - start_time:.6f} seconds\")\n",
    "\n",
    "start_time = time.time()\n",
    "print(calc_energy_vectorized(spins_test_configuration, nbr))\n",
    "end_time = time.time()\n",
    "print(f\"Time taken for calc_energy_vectorized: {end_time - start_time:.6f} seconds\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8158699c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling functions...\n",
      "Compilation complete. Starting simulation...\n",
      "L=10, T=2.27, MCS=5000\n",
      "Time elapsed: 0.5104 s\n",
      "Speed: 9.80e+05 updates/second\n"
     ]
    }
   ],
   "source": [
    "spins_last, energies, magnetizations = run_simulation(L=10, T=2.27, mcs_steps=5000, n_meas=100, spins=spins_test_configuration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49ba1aa",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string '-0.311927915' to int64 at row 0, column 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[56]\u001b[39m\u001b[32m, line 53\u001b[39m\n\u001b[32m     50\u001b[39m     energies = data[:]\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m energies\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m energies = \u001b[43mread_energies\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mbintest1.dat\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[38;5;66;03m# Perform binning analysis\u001b[39;00m\n\u001b[32m     55\u001b[39m bin_sizes, energy_errors, energy_means = binning_analysis(energies)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[56]\u001b[39m\u001b[32m, line 49\u001b[39m, in \u001b[36mread_energies\u001b[39m\u001b[34m(filename)\u001b[39m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mread_energies\u001b[39m(filename):\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m     data = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloadtxt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m     energies = data[:]\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m energies\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arthu\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\lib\\_npyio_impl.py:1397\u001b[39m, in \u001b[36mloadtxt\u001b[39m\u001b[34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows, quotechar, like)\u001b[39m\n\u001b[32m   1394\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(delimiter, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[32m   1395\u001b[39m     delimiter = delimiter.decode(\u001b[33m'\u001b[39m\u001b[33mlatin1\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1397\u001b[39m arr = \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomment\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcomment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1398\u001b[39m \u001b[43m            \u001b[49m\u001b[43mconverters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconverters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskiplines\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskiprows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43musecols\u001b[49m\u001b[43m=\u001b[49m\u001b[43musecols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1399\u001b[39m \u001b[43m            \u001b[49m\u001b[43munpack\u001b[49m\u001b[43m=\u001b[49m\u001b[43munpack\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mndmin\u001b[49m\u001b[43m=\u001b[49m\u001b[43mndmin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1400\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmax_rows\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_rows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquote\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquotechar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1402\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m arr\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arthu\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\lib\\_npyio_impl.py:1048\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(fname, delimiter, comment, quote, imaginary_unit, usecols, skiplines, max_rows, converters, ndmin, unpack, dtype, encoding)\u001b[39m\n\u001b[32m   1045\u001b[39m     data = _preprocess_comments(data, comments, encoding)\n\u001b[32m   1047\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m read_dtype_via_object_chunks \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1048\u001b[39m     arr = \u001b[43m_load_from_filelike\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1049\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomment\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcomment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquote\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1050\u001b[39m \u001b[43m        \u001b[49m\u001b[43mimaginary_unit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimaginary_unit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1051\u001b[39m \u001b[43m        \u001b[49m\u001b[43musecols\u001b[49m\u001b[43m=\u001b[49m\u001b[43musecols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskiplines\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskiplines\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_rows\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_rows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1052\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconverters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconverters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1053\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilelike\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilelike\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1054\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbyte_converters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbyte_converters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1056\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1057\u001b[39m     \u001b[38;5;66;03m# This branch reads the file into chunks of object arrays and then\u001b[39;00m\n\u001b[32m   1058\u001b[39m     \u001b[38;5;66;03m# casts them to the desired actual dtype.  This ensures correct\u001b[39;00m\n\u001b[32m   1059\u001b[39m     \u001b[38;5;66;03m# string-length and datetime-unit discovery (like `arr.astype()`).\u001b[39;00m\n\u001b[32m   1060\u001b[39m     \u001b[38;5;66;03m# Due to chunking, certain error reports are less clear, currently.\u001b[39;00m\n\u001b[32m   1061\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m filelike:\n",
      "\u001b[31mValueError\u001b[39m: could not convert string '-0.311927915' to int64 at row 0, column 1."
     ]
    }
   ],
   "source": [
    "def binning_analysis(data, max_bin_size=None):\n",
    "    \"\"\"\n",
    "    Perform binning analysis on time series data.\n",
    "    \n",
    "    Parameters:\n",
    "        data: (n_measurements,) time series array\n",
    "        max_bin_size: maximum bin size (~100 bins should remain)\n",
    "    \n",
    "    Returns:\n",
    "        bin_sizes: array of bin sizes (powers of 2)\n",
    "        bin_errors: standard error for each bin size\n",
    "        bin_means: mean value from binned data\n",
    "    \"\"\"\n",
    "    n_data = len(data)\n",
    "    \n",
    "    # Max bin size such that we have ~100 bins left\n",
    "    if max_bin_size is None:\n",
    "        max_bin_size = max(1, n_data // 100)\n",
    "    \n",
    "    # Bin sizes: 1, 2, 4, 8, 16, 32, ...\n",
    "    bin_sizes = []\n",
    "    bin_errors = []\n",
    "    bin_means = []\n",
    "    \n",
    "    m = 1\n",
    "    while m <= max_bin_size:\n",
    "        n_bins = n_data // m\n",
    "        \n",
    "        if n_bins < 1:\n",
    "            break\n",
    "        \n",
    "        # Bin the data\n",
    "        binned_data = np.array([np.mean(data[i*m:(i+1)*m]) for i in range(n_bins)])\n",
    "        \n",
    "        # Calculate statistics\n",
    "        bin_mean = np.mean(binned_data)\n",
    "        bin_std = np.std(binned_data, ddof=1)  # Sample std dev\n",
    "        bin_error = bin_std / np.sqrt(n_bins)  # Standard error of the mean\n",
    "        \n",
    "        bin_sizes.append(m)\n",
    "        bin_errors.append(bin_error)\n",
    "        bin_means.append(bin_mean)\n",
    "        \n",
    "        m *= 2\n",
    "    \n",
    "    return np.array(bin_sizes), np.array(bin_errors), np.array(bin_means)\n",
    "\n",
    "def read_energies(filename):\n",
    "    data = np.loadtxt(filename)\n",
    "    energies = data[:]\n",
    "    return energies\n",
    "\n",
    "energies = read_energies('bintest1.dat')\n",
    "# Perform binning analysis\n",
    "bin_sizes, energy_errors, energy_means = binning_analysis(energies)\n",
    "bin_sizes_m, mag_errors, mag_means = binning_analysis(np.abs(magnetizations))\n",
    "\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"TASK 3: BINNING ANALYSIS\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"\\nEnergy binning (E):\")\n",
    "print(f\"{'m':<8} {'<E>':<15} {'Error':<15}\")\n",
    "for m, em, err in zip(bin_sizes, energy_means, energy_errors):\n",
    "    print(f\"{m:<8} {em:<15.6f} {err:<15.6e}\")\n",
    "\n",
    "print(f\"\\nMagnetization binning (|M|):\")\n",
    "print(f\"{'m':<8} {'<|M|>':<15} {'Error':<15}\")\n",
    "for m, mm, err in zip(bin_sizes_m, mag_means, mag_errors):\n",
    "    print(f\"{m:<8} {mm:<15.6f} {err:<15.6e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
